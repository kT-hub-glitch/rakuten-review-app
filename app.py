# app.py â€”â€” æ¥½å¤©ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‹è‰²ï¼‹å¹´ä»£ â†’ Excel
# -----------------------------------------------
import streamlit as st
import requests, re, math, io
from bs4 import BeautifulSoup
import pandas as pd

st.title("æ¥½å¤©ãƒ¬ãƒ“ãƒ¥ãƒ¼ Scraperï¼ˆè‰²ãƒ»å¹´ä»£å¯¾å¿œï¼‰")

url = st.text_input("ãƒ¬ãƒ“ãƒ¥ãƒ¼1ãƒšãƒ¼ã‚¸ç›®ã® URL ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

if st.button("ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—"):
    if not url.strip():
        st.warning("URL ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        st.stop()

    @st.cache_data(show_spinner=True)
    def scrape(first_url: str):
        ua = {"User-Agent": "Mozilla/5.0"}
        reviews = []

        # ãƒšãƒ¼ã‚¸1
        res = requests.get(first_url, headers=ua, timeout=15)
        res.raise_for_status()
        soup = BeautifulSoup(res.text, "lxml")

        # æœ¬æ–‡div ãŒ 1ãƒ¬ãƒ“ãƒ¥ãƒ¼=1ä»¶
        box_list = soup.select(".review-body--3myhE")
        per_page = len(box_list) or 20  # å¿µã®ãŸã‚

        # ãƒšãƒ¼ã‚¸é€ã‚Šã®æœ€å¾Œã®æ•°å­—
        nums = [
            int(b.get_text()) for b in
            soup.select(".container--21I6f .page-button--152RB")
            if b.get_text().isdigit()
        ]
        pages = max(nums) if nums else 1

        def make_url(n: int):
            if "p=" in first_url:
                return re.sub(r"p=\d+", f"p={n}", first_url)
            if "page=" in first_url:
                return re.sub(r"page=\d+", f"page={n}", first_url)
            sep = "&" if "?" in first_url else "?"
            return f"{first_url}{sep}p={n}"

        for p in range(1, pages + 1):
            html = requests.get(make_url(p), headers=ua, timeout=15).text
            sp = BeautifulSoup(html, "lxml")

            for body_div in sp.select(".review-body--3myhE"):
                # ã‚¿ã‚¤ãƒˆãƒ«
                title_div = body_div.find_previous("div", class_="text-display--2xC98")
                title = title_div.get_text(strip=True) if title_div else ""
                # æœ¬æ–‡
                body = body_div.get_text(strip=True)
                # æ˜Ÿ
                rating_div = body_div.find_previous("div", class_="rating-container--1utdQ")
                star = rating_div.select_one(".text-container--2tSUW").get_text(strip=True) if rating_div else ""
                # æ—¥ä»˜
                date_div = body_div.find_previous("div", class_="text-display--2xC98",
                                                  string=lambda s: s and "æ³¨æ–‡æ—¥" in s)
                date = date_div.get_text(strip=True).replace("æ³¨æ–‡æ—¥ï¼š", "") if date_div else ""

                # â˜…â˜…â˜… è¿½ åŠ  è¦ ç´  â˜…â˜…â˜…
                # è‰² (ã‚¿ã‚¤ãƒ— / ã‚«ãƒ©ãƒ¼)
                color_div = body_div.find_next("div", class_="text-display--2xC98",
                                               string=lambda s: s and "ã‚«ãƒ©ãƒ¼:" in s)
                color = color_div.get_text(strip=True).replace("ã‚¿ã‚¤ãƒ—:", "").replace("ã‚«ãƒ©ãƒ¼:", "") if color_div else ""

                # å¹´ä»£ï¼ˆ10ä»£ã€œ80ä»£ã®æ•°å­—ï¼‹ä»£ãŒå…¥ã£ã¦ã„ã‚‹ã‹ã§åˆ¤æ–­ï¼‰
                age_div = body_div.find_next("div", class_="text-display--2xC98",
                                             string=lambda s: s and re.match(r"\d+ä»£", s))
                age = age_div.get_text(strip=True) if age_div else ""

                reviews.append({
                    "ãƒšãƒ¼ã‚¸": p,
                    "ã‚¿ã‚¤ãƒˆãƒ«": title,
                    "æœ¬æ–‡": body,
                    "æ˜Ÿ": star,
                    "æ—¥ä»˜": date,
                    "ã‚«ãƒ©ãƒ¼": color,
                    "å¹´ä»£": age
                })

        df = pd.DataFrame(reviews)
        bio = io.BytesIO()
        with pd.ExcelWriter(bio, engine="openpyxl") as w:
            df.to_excel(w, index=False, sheet_name="reviews")
        bio.seek(0)
        return df, bio

    try:
        df, excel_bytes = scrape(url)
        st.success(f"{len(df)} ä»¶ã‚’å–å¾—ã—ã¾ã—ãŸ")
        st.dataframe(df.head())

        st.download_button("ğŸ“¥ Excel ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                           data=excel_bytes,
                           file_name="rakuten_reviews.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
